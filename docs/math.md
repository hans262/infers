# math

## 对数
在数学中，对数是对求幂的逆运算，对数是相对于另两个数而言的。以a为底N的对数记做：
$$\log_{a}N$$

如果$N = a^x, (a>0, a \ne 1)$，即a的x次方等于N，那么x叫做以a为底N的对数，记做$\log_{a}N$，a叫做对数的底数，N叫做真数。

- 以10为底的对数叫做常用对数，记做$\lg N$
- 以e（e=2.71828...）为底的对数称为自然对数，记为$\ln N$
- 零没有对数
- 在实数范围内，负数无对数。在虚数范围内，负数是有对数的

## 方差
衡量一组数据离散程度的值，公式为$S = \sum_{i=1}^n(a_i - \mu)^2 / n$
```
  a = [50, 100, 100, 60, 50], n = 5
  μ = (50 + 100 + 100 + 60 + 50) / n
  S = ((50 - μ)^2 + (100 - μ)^2 + (100 - μ)^2 + (60 - μ)^2 + (50 - μ)^2) / n
```

## 求和符号
Σ是一个求和符号，英文名称Sigma，（大写Σ，小写σ）。
$$ \sum_{i=1}^n(a_i^2) $$
上式可理解为，以n个数据的平方和。

## 特征缩放
将一组数据映射到一个值域空间（0～1）的过程就是特征缩放，值域空间可以按需求设计。

机器学习中将特征缩放后再进行模型训练，往往可以加速模型的收敛速度和提高模型训练过程中的平稳性以防止跳过最优解。

标准特征缩放公式：
- $ x' = (x - min) / (max - min)$ 

```
  x' = (x - min) / (max - min)
  # 将结果映射到0~1之间

  average = min + (range / 2)
  x' = (x - average) / (max - min)
  # 将结果映射到-0.5~0.5之间
```

## 贝叶斯公式
是关于随机事件A和B的条件概率，在B发生的情况下A发生的可能性记做条件概率P(A|B)。贝叶斯公式：
$$P(B|A) = \frac{P(A|B) * P(B)}{P(A)} $$

一栋别墅在20年内被盗过2次，该别墅里的狗每周叫3次，已知盗贼入侵时狗叫的概率为0.9，求狗叫的时候盗贼入侵的概率？
```
P(A) = 3 / 7                   # 狗叫的概率
P(B) = 2 / 20 * 365            # 盗贼入侵的概率
P(A|B) = 0.9                   # 盗贼入侵时候狗叫的概率
P(B|A) = P(A|B) * P(B) / P(A)  # 狗叫的时候盗贼入侵的概率
P(A∩B) = P(A|B) * P(B)         # 盗贼入侵狗叫同时发生的概率
```

### 条件概率
当事件B发生时事件A发生的概率 -> P(A|B)

### 联合概率 
表示两个随机事件同时发生的概率 -> P(A∩B) 或 P(AB)

### 先验概率/后验概率
- 先验概率不是根据有关自然状态的全部资料测定的，而只是利用现有的材料(主要是历史资料)计算的；
- 后验概率使用了有关自然状态更加全面的资料，既有先验概率资料，也有补充资料；
- 上面的别墅被盗问题中P(A)、P(B)都是先验概率，他们都是基于历史数据的测定；